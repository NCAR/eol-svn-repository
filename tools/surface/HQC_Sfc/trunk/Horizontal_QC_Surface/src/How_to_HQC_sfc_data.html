<HTML>
<body bgcolor=white>
<plaintext>

                                                updated: 25 July 2000 LE Cully

             How to Horizontal Quality Control Surface Data
             ----------------------------------------------

        Four ordered steps are required to perform Horizontal Quality
        Control (HQC) on surface data that are in QCF format. Each step
        may consume a great deal of space and time depending on the size
        of the input files to each step. The user can expect that steps
        1., 3., and 4. will produce output files the same size as the
        input files to step 1. Step 2. will produce many small files
        depending on the frequency of the input data and the number of
        stations in those files. Step 2. may also require a considerable
        amount of cpu time and space to execute. See the attached diagram
        for each step. The four steps are:

        1. Shift UTC Data Times to Solar.
        2. Compute Solar Time Variances.
        3. Perform Horizontal Quality Control on Solar-0QC data.
        4. Shift Solar Data Times back to UTC.

        Each step is described in more detail below.


        1. Shift UTC Data Times to Solar.

           Step Input: "Raw" 0QC files with UTC times. (*YYMMDD.0qc)
           Step Output: 0QC files with times converted to solar. (solar_YYMMDD.0qc)

        The "raw" 0qc data records contain two times at the beginning
        of each record that are UTC time (UTC Nominal and UTC Actual).
        The UTC Actual time is the actual time that the observations were
        taken. The UTC Nominal times were determined during data conversion
        and are computed from the UTC Actual time.

        All HQC'd observations must be compared at like solar times so that
        station's are compared during similar atmospheric conditions.
        So, the first HQC step is to reset the UTC Nominal time in each
        record to a Solar time. The Solar time is computed based upon the station's
        locational relationship to UTC and the record's UTC Nominal time.
        Since we generally work with data in the continental U.S., the
        conversion to Solar time requires us to shift "back" from UTC to Solar time.
        This means that during HQC, parameters will be compared at like solar
        conditions (e.g., a 7am temperature at one station is compared to 7am
        temperatures that occurred at surrounding stations).

        When all the data times have been shifted "back" to Solar time, the
        data are ready to be processed through step 2. The program that
        shifts to and from UTC/SOLAR times is named NEW_convert_QCF_time.c.
        This program and the associated s/w is currently located in
        /rraid1/NEWQC/src. Read the s/w header to determine this s/w's
        assumptions and required input files. Sample input control files
        are also included in that area.


        2. Compute Solar Time Variances.

           Step Input: 0QC files with times converted to solar. (solar_YYMMDD.0qc)
           Step Output: Numerous YYYYJJJHHMM.sig.gz files (number depends on
                        data frequency).

        This step computes the variance values for 7 parameters (i.e., 3 pressures,
        temperature, dewpoint, wind speed, and wind direction) for every time and
        for every station at that time in the data. The main program that controls this
        processing is named compute_sigmasq.c.  This program and the associated s/w is
        currently located in /rraid1/NEWQC/src. Read the s/w header to determine this
        s/w's assumptions and required input files. The program header also explains
        the QCinit.inp input control file. The user can modify QCinit.inp to place
        the output sigmasq files into any location. Since generally there are numerous
        sigmasq files, it is recommended that the user place them in a seperate location.
        Please read the header documentation of compute_sigmasq.c carefully before
        running this program. Beware that this step may take considerable time depending
        on the frequency of the input data. The higher the frequency of the input
        data, the more output sigmasq files that will be generated and the longer
        the processing will take.


        3. Perform Horizontal Quality Control on Solar-0QC data.

           Step Input: 0QC files with times converted to solar. (solar_YYMMDD.0qc) AND
                       The numerous YYYYJJJHHMM.sig.gz files generated by step 2.
           Step Output: QCF files with solar times. (solar_YYMMDD.qcf)

        This step is the heart of the processing, since it actually performs
        the quality control processing.  Like step 2, this processing can take
        a great deal of time depending on the amount of data/stations being processed.
        Beware that adequate space and CPU time are available on the system
        BEFORE the processing begins.  If you are processing a lot of data, you might
        want to consider HQCing a section of days at a time. This can be done by setting values
        in the QCinit.inp input control file. See that file for more information.

        The s/w that controls the processing in this step is called main_qc.c and
        it is located in /rraid1/NEWQC/src. Several *.c and *.h files are required
        to build this s/w including date.*, locate_sigmasq.*, etc., so ensure that
        all required files exist before rebuilding main_qc. Since this is the most
        complicated of the four steps, please carefully read the s/w headers for
        assumptions, input files, etc. It is very important to read the
        s/w headers completely since certain input values may need to be updated
        before running main_qc.c (e.g., MAXNUMSTNS in local.h, SIGMA_PERIOD in gQC.h,
        MAX_NETWORKS and network[] in NEW_convert_QCF_time.c, Reference Longitude in
        TIMEinit_*.inp, etc.) User beware. Unexpected results can occur if all values
        are not properly set.

        For a complete description of the HQC processing please see the QC section
        in any GCIP surface composite readme on CODIAC or on a GCIP CD-ROM.  The readmes
        also describe the typical input alpha (tolerance) values used in HQC
        and the limit ranges they placed on the particular surface composite. The alpha
        values control which values will be flagged Good, Questionable, or Unlikely and you
        will see their affect when the final stnstat statistics are generated (See checkers below.)
        In general, the HQC computes an expect value for a particular station at a particular
        time based on the values of the surrounding stations (at that time) that fall
        within a preset Area of Influence (AOI). The AOI is set in the QCinit.inp file.
        The expected value is then compared to the actual value. The difference
        between the expected and the actual values is compared to Good, Questionable, and
        unlikely limits computed from the alpha (tolerance) values and the variance
        (sigmasq) value computed for this station at this time in step 2.  Once the quality
        of the parameter has been determined, this s/w sets the associated QC flag
        to G (Good), D (Questionable), B (Unlikely), or leaves it untouched as U. Gross
        limit checks are applied as the last step of this processing.  This may cause
        the QC flag to be reset. For instance if the temperature is set to good, but the
        gross limit checks determine that the dew point is greater than the temperature,
        the "Good" QC temperature flag will be reset to D for Questionable. Once the
        data have been HQC'd by this step, they are ready to have their times reset
        from Solar to their original UTC.

        It is wise to run the stnstat.f program on these Solar QCF files to
        see if the final statistics are satisfactory. If not, then the alpha
        values can be tweeked and this step rerun as many times as necessary.
        To rerun this step it is not necessary to redo any previous step unless
        an error in the raw data is found.  Note that when the HQC s/w needs
        a variance value to compute an expected value, this may spawn a searching
        process. During the search, the s/w looks ahead through the variance (sigmasq)
        files for an acceptable variance. Each search can look as far as 30 days
        in advance and any search may be unfruitful and not find a variance. This
        is hard to predict, but the more complete the data the fewer searched that
        will occur and the more likely that all searches done will be successful.
        Sparce data can lead to numerous searches that significantly slow this
        processing down. Also note that once a search is done, the variance files
        are backfilled and that same search will not occur again. So if the HQC
        process has to be rerun, but the variances do not have to be recomputed
        no searching will be done.  This also helps limit the number of repeat searches.



        4. Shift Solar Data Times back to UTC.

           Step Input: QCF files with solar times. (solar_YYMMDD.qcf)
           Step Output: QCF files with UTC times. (utc_YYMMDD.qcf)

        This step is similar to step 1 except that times are shifted
        from Solar to UTC. Use the NEW_convert_QCF_time.c program to
        shift the data back to UTC. This program and the associated s/w is currently
        located in /rraid1/NEWQC/src. Read the s/w header to determine this
        s/w's assumptions and required input files. Ensure that the "UTCtoSOLAR/
        SOLARtoUTC" flag is properly set to shift the data back to UTC. Shifting
        back to UTC requires an internal sorting step (s/w calls cosort sort.inp).
        The cosort utility must be accessible to this program. This is not
        required in step 1. Once this processing step has completed, the user can
        rename the utc_YYMMDD.qcf files to simply YYMMDD.qcf. These files are
        the matching HQC pairs to the input files to step 1. Beware that this
        step will generate the same amount of QCF data that this process began with.
        These are the final QCF data files that can given one last check (See below.)
        and then converted into EBUFR &/or loaded onto CODIAC.

        Once step 4. has completed, the HQC is done.


        Additional Checking:
        --------------------

        It is wise to rerun the composite, qcf, and duplicate checkers
        on the final utc_YYMMDD.qcf files. Although it is not likely
        that anything would be found at this stage, it is always a good
        idea to do one final check.   So rerun check_QCFcomp.c, check_QCF_rec.c
        and check_QCF_dups.c, along with at final "wc *.qcf". A description
        of these checkers can be found on the DPG web page and in the white
        "How to ...." book that the DPG maintains. Check that the final
        word counts match with the original UTC *.0qc data that was input
        into step 1.

        Run the stnstat.f program to compute final station and network
        statistics.

        Also, there are tools which examine the variance/sigmasq files
        computed in step 2. that determine the ranges of HQC flag limit
        values based upon the Normalization factors input into the HQC
        process (see QCinit.inp) in step 3.   Do the following to see
        plots of the computed variance/sigmasq files and to determine
        the numbers required to fill out table 3-2 in the CODIAC and
        CDROM Surface description documents, "Ranges of HQC flag limit
        values for Current project".


        1. Place a copy of the compute_var_cts (C program) in the
        directory where sigmasq files are located (e.g., /SIGMASQ_FILES).
        A copy of the C program can be found with all the other HQC
        src.

        2. Create a file called file_list.txt (expected by the compute_var_cts
        program) which contains a list of all the sigmasq files that you
        included in the calculations and plots.

        3. Run compute_var_cts  which generates the var_ct.out file.
        This output file contains a count of the binning of all the
        sigmasq (variance) values based upon Parameter (Parm). Note
        that sometimes the bins are clearly too large or too small
        and the compute_var_cts.c s/w must be updated and rerun.
        Also note that the parm numbers are described in the C program
        and are in the same order throughout the HQC process (press, press,
        press, temp, dewpt, windsp, winddir).   Provided the bins appear
        fairly even, the output at the end of the var_ct.out file will
        show 2 tables. The first table lists the range of values included
        to form the 95% ranges (calculated to fill out the tables in the
        surface doc table 3-2). The last table in the var_ct.out file
        is the exact table required for the HQC section of the Surface
        docs. Note the warning at the bottom on the fact that winds can
        not be more than 180 degrees off. Generally, the Q_high number
        must be reset to 180.00

        4. Plot the bins computed by compute_var_cts. You may need to
        redo setp 3 based upon these plots. You can run split_pts on
        the var_ct.out file to create seperate files containing each
        parms bins. This script is listed below and is based upon the
        fact that the exact form of the var_ct.out file never changes.
        Plot the output files of split_pts using gnuplot. Sample gnuplot
        code is also listed below.

        Sample Script split_pts:

----Begin script----
head -151 var_ct.out > j1
tail -150 j1 > stnp_var.out
/usr/bin/rm j1

head -301 var_ct.out > j1
tail -150 j1 > slp_var.out
/usr/bin/rm j1

head -451 var_ct.out > j1
tail -150 j1 > cslp_var.out
/usr/bin/rm j1

head -601 var_ct.out > j1
tail -150 j1 > temp_var.out
/usr/bin/rm j1

head -751 var_ct.out > j1
tail -150 j1 > dewpt_var.out
/usr/bin/rm j1

head -901 var_ct.out > j1
tail -150 j1 > wdsp_var.out
/usr/bin/rm j1

head -1051 var_ct.out > j1
tail -150 j1 > wdir_var.out
/usr/bin/rm j1
-------end script----

        Sample Gnuplot code:

           Note that you should use the info for the 95 percentile
        span begin and end values and plot those to mark that span.
        In the first example below, the 95 percentile  marks are
        at 4 and 78. These change for every new set of sigmasq files.

----begin sample Gnuplot code------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'stnp_var.ps'
set title "NESOB97 HSC Station Pressure Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set xrange [0:170]
set xtics (0,4,10,20,30,40,50,60,70,78,90,100,110,120,130,140,150,160,170)
set grid
plot "stnp_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'slp_var.ps'
set title "NESOB97 HSC Sea Level Pressure Variances"
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set xrange [0:200]
set xtics (0,5,10,20,30,40,50,60,70,80,96,110,120,130,140,150,160,170,180,190,200)
set grid
plot "slp_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'cslp_var.ps'
set title "NESOB97 HSC Calculated Sea Level Pressure Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set xrange [0:200]
set xtics (0,5,10,20,30,40,50,60,70,80,90,102,110,120,130,140,150,160,170,180,200)
set grid
plot "cslp_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'temp_var.ps'
set title "NESOB97 HSC Temperature Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set xrange [0:150]
set xtics (0,2,4,10,20,30,43,50,60,70,80,90,100,110,120,130,140,150)
set grid
plot "temp_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'dewpt_var.ps'
set title "NESOB97 HSC Dew Point Temperature Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set xrange [0:150]
set xtics (0,3,5,10,20,30,44,50,60,70,80,90,100,110,120,130,140,150)
set grid
plot "dewpt_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'wdsp_var.ps'
set title "NESOB97 HSC Wind Speed Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set yrange[0:36000]
set xrange[0:15]
set xtics (0,1,2,3,4,5,6,7,8,9.25,10,11,12,13,14,15)
set grid
plot "wdsp_var.out" using 3:4 with boxes
--------------------
set terminal postscript landscape monochrome dashed "Helvetica" 14
set output 'wdir_var.ps'
set title "NESOB97 HSC Wind Direction Variances "
set xlabel "Variance Values" 0,0
set ylabel "Counts"
set nokey
set yrange[0:15000]
set xrange[0:26000]
set xtics (0,2250,4000,6000,8000,10000,12000,14000,17250,20000,22000,24000,26000)
set grid
plot "wdir_var.out" using 3:4 with boxes
---end of sample gnuplot commands-----
